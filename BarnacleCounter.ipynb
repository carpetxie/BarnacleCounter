{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModuleSpec' object has no attribute 'UNet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToTensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mUNetModel\u001b[39;00m \n\u001b[0;32m----> 8\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mUNetModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUNet\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munet_model_weights.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmsu\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModuleSpec' object has no attribute 'UNet'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import CropBarnacles\n",
    "import cv2 as cv\n",
    "import torch\n",
    "from torchvision.transforms import ToTensor\n",
    "import UNetModel \n",
    "\n",
    "model = UNetModel.UNet(1)\n",
    "model.load_state_dict(torch.load(\"unet_model_weights.pth\", map_location=torch.device('mps')))\n",
    "model.eval()\n",
    "\n",
    "def BarnacleCounter(image_path, min_area):\n",
    "    input_img, x, y, w, h = CropBarnacles.Crop(image_path)\n",
    "    img_tensor = ToTensor()(input_img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        mask = model(img_tensor).squeeze().numpy()\n",
    "    mask = (mask > 0.5).astype('uint8') * 255\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "    large_contours = [contour for contour in contours if cv.contourArea(contour) >= min_area]\n",
    "    return len(large_contours)\n",
    "\n",
    "image_path = 'unseen_img1.png'\n",
    "count = BarnacleCounter(image_path, 500)\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
